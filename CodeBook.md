
# Introduction

This CodeBook contains additional information about the R script (`run_analysis.R`) transformations and the data used. This work is completed as project assignment for Coursera Data Science - Getting and Cleanind Data.

## Source data set information

Source data is from Human Activity Recognition database, built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

I encourage users of the script to view the README.txt file for further details about this dataset.

The complete [data set](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip ) is available at [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)

## Files and attribute information

Files used in the assignment:

* `features.txt`: List of all features.
* `activity_labels.txt`: Links the class labels with their activity name.
* `train/X_train.txt`: Training set.
* `train/y_train.txt`: Training labels.
* `test/X_test.txt`: Test set.
* `test/y_test.txt`: Test labels.
* `train/subject_train.txt`: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 
* `train/subject_test.txt`: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 


* additional file `features_info.txt` describes the measurements that were recorded. This assignment takes into count mean(): Mean value and std(): Standard deviation calculation. Other measurements which are not included in this work are descriped in the file.

* There is an output file generated by the script. This contains the tidy data set: tidy_mean.txt. The script writes this file into the path defined in `setwd()` function described in the beginning of the script.

Attribute Information:

For each record in the dataset it is provided:
- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
- Triaxial Angular velocity from the gyroscope.
- A 561-feature vector with time and frequency domain variables.
- Its activity label.
- An identifier of the subject who carried out the experiment. 
	

## Script

R script `run_analysis.R` performs data manipulation in order that mainly follows five steps provided in the course assignments.

* Script uses `setwd()` function, and assumes that the source data is located there in the original format. Also the tidy data file is written to the working directory path defined.

* In the first step data is loaded from multiple source files and combined using `rbind()` function. X and Y training and test set are combined as well as subject train and test sets.
* Second step loads the measurements from file `features.txt`. Subset of only required measurements: mean and std is created by applying `grep` function into second column of all measurement to find only mean and std measurements. After this a subset of data is created which only contains data with mean and std values.
* Third and fourt step in the scrips sets label for the X subset data. `names()` function is used to set name for column for the subset data from measurements data. Activity descriptions are red from the activity labels file and set to combined Y data. After labeling and correcting variable names, one combined data set is created containing X, Y and subject data.
* In the last step a tidy data set is created. This contains aggregated data where `mean` is calculated to numeric variables. Data is grouped by subject and activity.

## Variables 

* x_train, y_train, subject_train, x_test, y_test, subject_test are containing data from separate files.
* x_data is combined data of x_test, x_train as y_data is from y_test, y_train and subject_data is from subject_test and subject_train
* all_measurements contains data from `features.txt` file. measurements is subset of this, containing only mean and std measurements. 
* x_data_sub is subset of x_data, where only mean and std data is selected.
* activity contains data from `activity_labels.txt`
* data is combined data set of subject_data, y_data, x_data_sub
* tidy is the final data set required by the course assignment. This data set contains aggregated data of mean by subject id and activity. The content of data set is calculated with `aggregate()` function. 






